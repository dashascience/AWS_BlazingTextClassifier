{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import botocore\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!pip install --disable-pip-version-check -q nltk==3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name AmazonSageMaker-ExecutionRole-20210831T104726 to get Role path.\n",
      "Assuming role was created in SageMaker AWS console, as the name contains `AmazonSageMaker-ExecutionRole`. Defaulting to Role ARN with service-role in path. If this Role ARN is incorrect, please add IAM read permissions to your role or supply the Role Arn directly.\n"
     ]
    }
   ],
   "source": [
    "sm = boto3.client(service_name='sagemaker')\n",
    "sess = sagemaker.Session(sagemaker_client=sm)\n",
    "\n",
    "bucket = 'daria-hlibova-test'\n",
    "region = sess.boto_region_name\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://daria-hlibova-test/SMSSpamCollection.txt to ./SMSSpamCollection.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!aws s3 cp 's3://daria-hlibova-test/SMSSpamCollection.txt' ./\n",
    "path = './SMSSpamCollection.txt'\n",
    "df = pd.read_csv(path, sep = '\\t', header = None)\n",
    "df.columns = ['label', 'text']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode response\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for tokenizing text and remove punctuations\n",
    "def join_text_label(x):\n",
    "    words = nltk.word_tokenize(x['text'])\n",
    "    cleaned_text= \" \".join([word.lower() for word in words if word.isalnum()])\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for prepraring label for BlazingText algorithm\n",
    "def prepare_label(x):\n",
    "    return f\"__label__{x['label_encoded']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prepared_text'] = df.apply(lambda x:join_text_label(x), axis = 1)\n",
    "df['label_encoded'] = df.apply(lambda x:prepare_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blazingtext = df[['label_encoded','prepared_text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>prepared_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>nah i do think he goes to usf he lives around ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_encoded                                      prepared_text\n",
       "0    __label__0  go until jurong point crazy available only in ...\n",
       "1    __label__0                            ok lar joking wif u oni\n",
       "2    __label__1  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3    __label__0        u dun say so early hor u c already then say\n",
       "4    __label__0  nah i do think he goes to usf he lives around ..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blazingtext.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset for train and test sets\n",
    "df_train, df_vtest = train_test_split(df_blazingtext, \n",
    "                                           test_size=0.2,\n",
    "                                           stratify=df_blazingtext['label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Upload Dataset to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "blazingtext_train_path = './train.csv'\n",
    "df_train.to_csv(blazingtext_train_path, index=False, header=False, sep=' ')\n",
    "\n",
    "blazingtext_test_path = './val.csv'\n",
    "df_vtest.to_csv(blazingtext_test_path, index=False, header=False, sep=' ')\n",
    "\n",
    "train_s3_uri = sess.upload_data(bucket='daria-hlibova-test', key_prefix='blazingtext/data', path=blazingtext_train_path)\n",
    "test_s3_uri = sess.upload_data(bucket='daria-hlibova-test', key_prefix='blazingtext/data', path=blazingtext_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cntainer image to use for training with the BlazingText algorithm.\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    region=region,\n",
    "    framework='blazingtext'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an estimator instance\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=30,\n",
    "    max_run=7200,\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settinmg hyperparameters\n",
    "estimator.set_hyperparameters(mode='supervised',   # supervised (text classification)\n",
    "                              epochs=10,           # number of complete passes through the dataset\n",
    "                              learning_rate=0.01,  # step size for the  numerical optimizer\n",
    "                              min_count=5,         # discard words that appear less than this number                             \n",
    "                              vector_dim=300,      # number of dimensions in vector space\n",
    "                              word_ngrams=2)       # number of words in a word n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating train data channel\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    train_s3_uri,\n",
    "    distribution='FullyReplicated', \n",
    "    content_type='text/plain', \n",
    "    s3_data_type='S3Prefix'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating test data channel\n",
    "test_data = sagemaker.inputs.TrainingInput(\n",
    "    test_s3_uri,\n",
    "    distribution='FullyReplicated', \n",
    "    content_type='text/plain', \n",
    "    s3_data_type='S3Prefix'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {\n",
    "    'train': train_data,\n",
    "    'validation': test_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job Name:  blazingtext-2022-01-15-10-57-02-937\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model\n",
    "estimator.fit(\n",
    "    inputs=data_channels,\n",
    "    wait=False,\n",
    "    logs = True\n",
    ")\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print('Training Job Name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-2#/jobs/blazingtext-2022-01-15-10-57-02-937\">Training job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training job</a></b>'.format(region, training_job_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-2#logStream:group=/aws/sagemaker/TrainingJobs;prefix=blazingtext-2022-01-15-10-57-02-937;streamFilter=typeLogStreamPrefix\">CloudWatch logs</a> (after about 5 minutes)</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch logs</a> (after about 5 minutes)</b>'.format(region, training_job_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-01-15 10:57:03 Starting - Starting the training job\n",
      "2022-01-15 10:57:05 Starting - Launching requested ML instances........\n",
      "2022-01-15 10:57:51 Starting - Preparing the instances for training...................\n",
      "2022-01-15 10:59:31 Downloading - Downloading input data...\n",
      "2022-01-15 10:59:51 Training - Downloading the training image...\n",
      "2022-01-15 11:00:12 Training - Training image download completed. Training in progress....\n",
      "2022-01-15 11:00:33 Uploading - Uploading generated training model..."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.latest_training_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating endpoint\n",
    "\n",
    "%%time\n",
    "\n",
    "text_classifier = estimator.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m5.large',\n",
    "                                   serializer=sagemaker.serializers.JSONSerializer(),\n",
    "                                   deserializer=sagemaker.deserializers.JSONDeserializer())\n",
    "\n",
    "print()\n",
    "print('Endpoint name:  {}'.format(text_classifier.endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, text_classifier.endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['i will be later',\n",
    "           'call me'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = [' '.join(nltk.word_tokenize(review)) for review in reviews]\n",
    "\n",
    "payload = {\"instances\" : tokenized_reviews}\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "predictions = text_classifier.predict(data=payload)\n",
    "for prediction in predictions:\n",
    "    print('Predicted class: {}'.format(prediction['label'][0].lstrip('__label__')))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
